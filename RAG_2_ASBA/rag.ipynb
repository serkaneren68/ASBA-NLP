{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb966f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088c671",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCMImjFMxNmcgPdIuAK9UkAkDPSDN_8YMo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b151f299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eren_s\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7f066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/\",)\n",
    "    # bs_kwargs=dict(\n",
    "    #     parse_only=bs4.SoupStrainer(\n",
    "    #         class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "    #     )\n",
    "    # ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='49e78605-d333-4482-8e5d-07c844af247f', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US', 'start_index': 4287}, page_content='To manage the complexity, AUTOSAR introduced a modular architecture with layers to separate hardware-independent application software from hardware-oriented software.The upper layer,\\xa0Application Software (ASW)\\xa0hosts the application functions as individual software components (SWC).The lower layer, the\\xa0Basic Software (BSW)\\xa0includes low level software like services and hardware specific software.Between these layers is an abstraction layer called the\\xa0Runtime Environment (RTE)\\xa0that manages the interface between the two other layers.\\xa0The AUTOSAR architecture also provides a way to decouple the applications from the hardware infrastructure. AUTOSAR introduced the concept of Virtual Functional Bus (VFB) which makes it possible for the SWCs to interact independently from where they are executed in the system (inside one ECU or on different ECUs). \\xa0As SWCs are allocated to the various ECUs, the virtual connections are mapped to local connections (intra-ECU) or onto network communication'), Document(id='eb506b2e-5524-44d5-98d8-b4e590490964', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US'}, page_content='To manage the complexity, AUTOSAR introduced a modular architecture with layers to separate hardware-independent application software from hardware-oriented software.The upper layer,\\xa0Application Software (ASW)\\xa0hosts the application functions as individual software components (SWC).The lower layer, the\\xa0Basic Software (BSW)\\xa0includes low level software like services and hardware specific software.Between these layers is an abstraction layer called the\\xa0Runtime Environment (RTE)\\xa0that manages the interface between the two other layers.\\xa0The AUTOSAR architecture also provides a way to decouple the applications from the hardware infrastructure. AUTOSAR introduced the concept of Virtual Functional Bus (VFB) which makes it possible for the SWCs to interact independently from where they are executed in the system (inside one ECU or on different ECUs). \\xa0As SWCs are allocated to the various ECUs, the virtual connections are mapped to local connections (intra-ECU) or onto network communication'), Document(id='78b5bca4-b422-4084-a738-44fcb15de6f5', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US', 'start_index': 15662}, page_content='Group 26 \\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tAll Videos\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\nPopular Videos \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRequest Evaluation License \\n\\n\\n\\nIf you would like to try out our tools, we will gladly provide an evaluation license free of charge.\\xa0Evaluations include a free launch workshop and also provide an opportunity for you to meet one-on-one with our support and engineering teams. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nRequest License\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSchedule a Meeting \\n\\n\\n\\nDo you have any questions or want to see our tools in action? If so, please use the link below to schedule a meeting, where a member of our engineering team will be happy to show you the features and use cases and directly answer any questions you might have. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nSchedule Meeting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nJoin our newsletter'), Document(id='8623ba0e-bd42-42b9-8edb-a6dfe8387600', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US'}, page_content='Group 26 \\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tAll Videos\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\nPopular Videos \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRequest Evaluation License \\n\\n\\n\\nIf you would like to try out our tools, we will gladly provide an evaluation license free of charge.\\xa0Evaluations include a free launch workshop and also provide an opportunity for you to meet one-on-one with our support and engineering teams. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nRequest License\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSchedule a Meeting \\n\\n\\n\\nDo you have any questions or want to see our tools in action? If so, please use the link below to schedule a meeting, where a member of our engineering team will be happy to show you the features and use cases and directly answer any questions you might have. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nSchedule Meeting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nJoin our newsletter')]\n",
      "\n",
      "\n",
      "Answer: ASW stands for Application Software, which is the upper layer in the AUTOSAR modular architecture. It hosts hardware-independent application functions as individual software components (SWC). This layer is separated from hardware-oriented software.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is ASW?\"})\n",
    "print(f\"Context: {response['context']}fo\\n\\n\")\n",
    "print(f\"Answer: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "059628b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='49e78605-d333-4482-8e5d-07c844af247f', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US', 'start_index': 4287}, page_content='To manage the complexity, AUTOSAR introduced a modular architecture with layers to separate hardware-independent application software from hardware-oriented software.The upper layer,\\xa0Application Software (ASW)\\xa0hosts the application functions as individual software components (SWC).The lower layer, the\\xa0Basic Software (BSW)\\xa0includes low level software like services and hardware specific software.Between these layers is an abstraction layer called the\\xa0Runtime Environment (RTE)\\xa0that manages the interface between the two other layers.\\xa0The AUTOSAR architecture also provides a way to decouple the applications from the hardware infrastructure. AUTOSAR introduced the concept of Virtual Functional Bus (VFB) which makes it possible for the SWCs to interact independently from where they are executed in the system (inside one ECU or on different ECUs). \\xa0As SWCs are allocated to the various ECUs, the virtual connections are mapped to local connections (intra-ECU) or onto network communication'),\n",
       " Document(id='eb506b2e-5524-44d5-98d8-b4e590490964', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US'}, page_content='To manage the complexity, AUTOSAR introduced a modular architecture with layers to separate hardware-independent application software from hardware-oriented software.The upper layer,\\xa0Application Software (ASW)\\xa0hosts the application functions as individual software components (SWC).The lower layer, the\\xa0Basic Software (BSW)\\xa0includes low level software like services and hardware specific software.Between these layers is an abstraction layer called the\\xa0Runtime Environment (RTE)\\xa0that manages the interface between the two other layers.\\xa0The AUTOSAR architecture also provides a way to decouple the applications from the hardware infrastructure. AUTOSAR introduced the concept of Virtual Functional Bus (VFB) which makes it possible for the SWCs to interact independently from where they are executed in the system (inside one ECU or on different ECUs). \\xa0As SWCs are allocated to the various ECUs, the virtual connections are mapped to local connections (intra-ECU) or onto network communication'),\n",
       " Document(id='78b5bca4-b422-4084-a738-44fcb15de6f5', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US', 'start_index': 15662}, page_content='Group 26 \\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tAll Videos\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\nPopular Videos \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRequest Evaluation License \\n\\n\\n\\nIf you would like to try out our tools, we will gladly provide an evaluation license free of charge.\\xa0Evaluations include a free launch workshop and also provide an opportunity for you to meet one-on-one with our support and engineering teams. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nRequest License\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSchedule a Meeting \\n\\n\\n\\nDo you have any questions or want to see our tools in action? If so, please use the link below to schedule a meeting, where a member of our engineering team will be happy to show you the features and use cases and directly answer any questions you might have. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nSchedule Meeting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nJoin our newsletter'),\n",
       " Document(id='8623ba0e-bd42-42b9-8edb-a6dfe8387600', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US'}, page_content='Group 26 \\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tAll Videos\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\nPopular Videos \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRequest Evaluation License \\n\\n\\n\\nIf you would like to try out our tools, we will gladly provide an evaluation license free of charge.\\xa0Evaluations include a free launch workshop and also provide an opportunity for you to meet one-on-one with our support and engineering teams. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nRequest License\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSchedule a Meeting \\n\\n\\n\\nDo you have any questions or want to see our tools in action? If so, please use the link below to schedule a meeting, where a member of our engineering team will be happy to show you the features and use cases and directly answer any questions you might have. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nSchedule Meeting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nJoin our newsletter')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c16839c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 17990\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/\",)\n",
    "    # bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2f43af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 27 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79a80b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5672950c-76d7-497a-aa3f-8fde336c35a4', 'bf1f82c0-21e5-4ba5-bb0b-9bab9d9bf3c0', '147df4cc-2bdf-49e2-b031-9be9761d209b']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b3433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee807068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b3a4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='49e78605-d333-4482-8e5d-07c844af247f', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US', 'start_index': 4287}, page_content='To manage the complexity, AUTOSAR introduced a modular architecture with layers to separate hardware-independent application software from hardware-oriented software.The upper layer,\\xa0Application Software (ASW)\\xa0hosts the application functions as individual software components (SWC).The lower layer, the\\xa0Basic Software (BSW)\\xa0includes low level software like services and hardware specific software.Between these layers is an abstraction layer called the\\xa0Runtime Environment (RTE)\\xa0that manages the interface between the two other layers.\\xa0The AUTOSAR architecture also provides a way to decouple the applications from the hardware infrastructure. AUTOSAR introduced the concept of Virtual Functional Bus (VFB) which makes it possible for the SWCs to interact independently from where they are executed in the system (inside one ECU or on different ECUs). \\xa0As SWCs are allocated to the various ECUs, the virtual connections are mapped to local connections (intra-ECU) or onto network communication'), Document(id='eb506b2e-5524-44d5-98d8-b4e590490964', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US'}, page_content='To manage the complexity, AUTOSAR introduced a modular architecture with layers to separate hardware-independent application software from hardware-oriented software.The upper layer,\\xa0Application Software (ASW)\\xa0hosts the application functions as individual software components (SWC).The lower layer, the\\xa0Basic Software (BSW)\\xa0includes low level software like services and hardware specific software.Between these layers is an abstraction layer called the\\xa0Runtime Environment (RTE)\\xa0that manages the interface between the two other layers.\\xa0The AUTOSAR architecture also provides a way to decouple the applications from the hardware infrastructure. AUTOSAR introduced the concept of Virtual Functional Bus (VFB) which makes it possible for the SWCs to interact independently from where they are executed in the system (inside one ECU or on different ECUs). \\xa0As SWCs are allocated to the various ECUs, the virtual connections are mapped to local connections (intra-ECU) or onto network communication'), Document(id='78b5bca4-b422-4084-a738-44fcb15de6f5', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US', 'start_index': 15662}, page_content='Group 26 \\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tAll Videos\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\nPopular Videos \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRequest Evaluation License \\n\\n\\n\\nIf you would like to try out our tools, we will gladly provide an evaluation license free of charge.\\xa0Evaluations include a free launch workshop and also provide an opportunity for you to meet one-on-one with our support and engineering teams. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nRequest License\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSchedule a Meeting \\n\\n\\n\\nDo you have any questions or want to see our tools in action? If so, please use the link below to schedule a meeting, where a member of our engineering team will be happy to show you the features and use cases and directly answer any questions you might have. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nSchedule Meeting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nJoin our newsletter'), Document(id='8623ba0e-bd42-42b9-8edb-a6dfe8387600', metadata={'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/', 'title': 'AUTOSAR architecture - What Every Developer Should Know', 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?', 'language': 'en-US'}, page_content='Group 26 \\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tAll Videos\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\nPopular Videos \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRequest Evaluation License \\n\\n\\n\\nIf you would like to try out our tools, we will gladly provide an evaluation license free of charge.\\xa0Evaluations include a free launch workshop and also provide an opportunity for you to meet one-on-one with our support and engineering teams. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nRequest License\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSchedule a Meeting \\n\\n\\n\\nDo you have any questions or want to see our tools in action? If so, please use the link below to schedule a meeting, where a member of our engineering team will be happy to show you the features and use cases and directly answer any questions you might have. \\n\\n\\n\\n\\n\\n\\n\\nGroup 26 \\nSchedule Meeting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nJoin our newsletter')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'ASW stands for Application Software, which is the upper layer in the AUTOSAR modular architecture. It hosts the application functions as individual software components (SWC). This layer is designed to be hardware-independent.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What is ASW?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "135ca5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.btc-embedded.com/autosar-architecture-what-every-function-developer-should-know/',\n",
       " 'title': 'AUTOSAR architecture - What Every Developer Should Know',\n",
       " 'description': 'AUTOSAR was introduced 15 years ago as a standardized architecture to develop complex automotive applications. What are the keys concepts?',\n",
       " 'language': 'en-US',\n",
       " 'start_index': 12,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed6665d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "499bdb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "583a61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ad28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac587b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f71618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9c280a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b19f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (a787ccae-2462-47ea-8b3d-f076fa686f6f)\n",
      " Call ID: a787ccae-2462-47ea-8b3d-f076fa686f6f\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is the process of breaking down a complicated task into smaller, simpler, and more manageable steps. This technique allows an agent to plan ahead and address complex problems by transforming them into multiple manageable sub-tasks. It can be achieved through methods like Chain of Thought prompting, where a model is instructed to \"think step by step.\"\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af279d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc1234\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "458185d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (a7a2bb9f-21ce-4dc1-9a29-ccc5ebf150ce)\n",
      " Call ID: a7a2bb9f-21ce-4dc1-9a29-ccc5ebf150ce\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is the process of breaking down complicated tasks into smaller, more manageable steps, allowing an agent to plan ahead. This technique helps transform big tasks into multiple manageable parts, enhancing performance on complex problems. It can be achieved through LLMs with simple prompting, task-specific instructions, or human inputs.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43eb25a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Benim adım Ne?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Üzgünüm, adınızı bilmiyorum.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Benim adım Ne?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08721275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e3e0fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (69aaaf0a-cadc-4a31-ad9d-a9d35876c86c)\n",
      " Call ID: 69aaaf0a-cadc-4a31-ad9d-a9d35876c86c\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (9bee4423-c313-4e44-882e-1c3889b29a56)\n",
      " Call ID: 9bee4423-c313-4e44-882e-1c3889b29a56\n",
      "  Args:\n",
      "    query: extensions of LLM prompting for Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The standard methods for Task Decomposition primarily involve Large Language Models (LLMs) with prompting. This can be achieved through:\n",
      "\n",
      "1.  **Simple Prompting:** Using direct prompts such as \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\"\n",
      "2.  **Task-Specific Instructions:** Providing specialized instructions tailored to the task, like \"Write a story outline.\" for novel writing.\n",
      "3.  **Human Inputs:** Incorporating human guidance to break down tasks.\n",
      "\n",
      "Common extensions of LLM prompting for Task Decomposition include:\n",
      "\n",
      "*   **Chain of Thought (CoT):** This technique instructs the model to \"think step by step,\" breaking down complex tasks into smaller, more manageable steps. It enhances performance and offers insight into the model's reasoning.\n",
      "*   **Tree of Thoughts (ToT):** ToT expands on CoT by exploring multiple reasoning paths at each step. It generates a tree-like structure of thoughts, with each step potentially having multiple possibilities. Search processes like Breadth-First Search (BFS) or Depth-First Search (DFS) can then be used, with states evaluated by a classifier or majority vote.\n",
      "*   **LLM+P (LLM plus Planner):** This approach outsources long-horizon planning to an external classical planner. The LLM translates the problem into Planning Domain Definition Language (PDDL), a classical planner generates a PDDL plan, and the LLM then translates the plan back into natural language. This method assumes the availability of domain-specific PDDL and a suitable planner.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
    "\n",
    "input_message = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
